import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yaml
import os
from itertools import combinations
import re
from typing import List, Tuple, Dict

def create_nonuniform_quantiles(n_quantiles: int, edge_density: float = 0.3) -> np.ndarray:
    """
    Create non-uniform quantile spacing with higher density at edges.
    """
    n_edge = int(n_quantiles * edge_density)
    n_middle = n_quantiles - (2 * n_edge)
    
    start_points = np.exp(np.linspace(np.log(1e-6), np.log(0.1), n_edge))
    end_points = 1 - np.exp(np.linspace(np.log(0.1), np.log(1e-6), n_edge))
    middle_points = np.linspace(0.1, 0.9, n_middle)
    
    quantiles = np.concatenate([[0], start_points, middle_points, end_points, [1]])
    return np.unique(quantiles)

def quantile_minima(df: pd.DataFrame, x_col: str, z_col: str, 
                   n_quantiles: int = 70, 
                   edge_density: float = 0.3,
                   min_points: int = 3) -> pd.DataFrame:
    """
    Calculate quantile minima with increased density at the extremes.
    """
    quantiles = create_nonuniform_quantiles(n_quantiles, edge_density)
    x_bounds = df[x_col].quantile(quantiles)
    
    minima = []
    for i in range(len(x_bounds)-1):
        mask = (df[x_col] >= x_bounds[i]) & (df[x_col] < x_bounds[i+1])
        if mask.sum() >= min_points:
            quantile_data = df[mask]
            min_point = quantile_data.loc[quantile_data[z_col].idxmin()]
            minima.append({
                x_col: min_point[x_col],
                z_col: min_point[z_col],
                'n_points': mask.sum()
            })
    
    result_df = pd.DataFrame(minima)
    
    global_min = df.loc[df[z_col].idxmin()]
    min_point_dict = {
        x_col: global_min[x_col],
        z_col: global_min[z_col],
        'n_points': 1
    }
    
    if len(result_df) == 0 or not any((result_df[x_col] == global_min[x_col]) & 
                                     (result_df[z_col] == global_min[z_col])):
        result_df = pd.concat([result_df, pd.DataFrame([min_point_dict])], 
                            ignore_index=True)
    
    return result_df.sort_values(x_col)

def load_yaml_data(yaml_path: str) -> Tuple[List[List[int]], List[str]]:
    """
    Load coordinate list and string list from YAML file.
    """
    with open(yaml_path, 'r') as file:
        data = yaml.safe_load(file)
        return data['coordinate_list'], data['string_list']

def group_strings(strings: List[str]) -> Dict[str, List[str]]:
    """
    Group strings based on common prefixes and suffixes.
    """
    groups = {}
    for s in strings:
        match = re.match(r'([a-zA-Z]+_).*?(_[a-zA-Z]+)$', s)
        if match:
            prefix, suffix = match.groups()
            pattern = f"{prefix}*{suffix}"
            if pattern not in groups:
                groups[pattern] = []
            groups[pattern].append(s)
    return groups

def coordinate_to_string(coord: List[int]) -> str:
    """
    Convert coordinate list to string with "Troublesome" prefix.
    """
    coord_str = ''.join(str(x) for x in coord)
    return f"Troublesome {coord_str}"

def match_groups_to_coordinates(string_groups: Dict[str, List[str]], 
                              coordinates: List[List[int]]) -> List[Tuple[List[str], str]]:
    """
    Match string groups to coordinates in order.
    """
    matched_pairs = []
    coord_strings = [coordinate_to_string(coord) for coord in coordinates]
    
    grouped_strings = list(string_groups.values())
    
    if len(grouped_strings) == len(coordinates):
        matched_pairs = list(zip(grouped_strings, coord_strings))
    
    return matched_pairs

def create_scatter_plots(df: pd.DataFrame, str_cols: List[str], trouble_col: str, 
                        output_dir: str = 'results'):
    """
    Create scatter plots for string columns vs trouble column.
    """
    dir_name = f"{str_cols[0]}_{str_cols[1]}" if len(str_cols) > 1 else str_cols[0]
    os.makedirs(os.path.join(output_dir, dir_name), exist_ok=True)
    
    plt.figure(figsize=(10, 8))
    
    if len(str_cols) > 1:
        # Create 2D scatter plot with intensity color
        scatter = plt.scatter(df[str_cols[0]], df[str_cols[1]], 
                            c=np.log10(df[trouble_col]),
                            cmap='viridis',
                            alpha=0.6)
        
        plt.xlabel(str_cols[0])
        plt.ylabel(str_cols[1])
        plt.title(f'{str_cols[0]} vs {str_cols[1]}\nColor: log10({trouble_col})')
    else:
        # Create single dimension scatter plot
        scatter = plt.scatter(df[str_cols[0]], df[trouble_col],
                            c=np.log10(df[trouble_col]),
                            cmap='viridis',
                            alpha=0.6)
        
        plt.xlabel(str_cols[0])
        plt.ylabel(trouble_col)
        plt.title(f'{str_cols[0]} vs {trouble_col}')
    
    cbar = plt.colorbar(scatter)
    cbar.set_label(f'log10({trouble_col})')
    
    plt.savefig(os.path.join(output_dir, dir_name, f'{dir_name}_scatter.png'),
               dpi=300, bbox_inches='tight')
    plt.close()
    
    # Save data
    cols_to_save = str_cols + [trouble_col]
    subset_df = df[cols_to_save]
    subset_df.to_csv(os.path.join(output_dir, dir_name, f'{dir_name}_data.csv'),
                    index=False)

def create_minima_plots(df: pd.DataFrame, str_cols: List[str], trouble_col: str, 
                       output_dir: str = 'minima_results'):
    """
    Create minima plots with enhanced quantile analysis.
    """
    os.makedirs(output_dir, exist_ok=True)
    
    for col in str_cols:
        minima_df = quantile_minima(df, col, trouble_col, n_quantiles=70, edge_density=0.3)
        
        plt.figure(figsize=(10, 8))
        
        plt.scatter(df[col], df[trouble_col], alpha=0.3, label='Original Data')
        
        plt.plot(minima_df[col], minima_df[trouble_col], 'r-', 
                label='Quantile Minima', linewidth=2)
        
        sizes = np.clip(minima_df['n_points'] * 5, 50, 200)
        plt.scatter(minima_df[col], minima_df[trouble_col], 
                   s=sizes, color='red', alpha=0.5,
                   label='Minima Points')
        
        plt.xlabel(col)
        plt.ylabel(trouble_col)
        plt.title(f'{col} vs {trouble_col} with Enhanced Quantile Minima')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.savefig(os.path.join(output_dir, f'{col}_minima.png'),
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        minima_df.to_csv(os.path.join(output_dir, f'{col}_minima.csv'),
                        index=False)

def process_single_node(df: pd.DataFrame, output_dir: str = 'results'):
    """
    Process data when there's only one coordinate node.
    Uses all columns vs the last column as intensity.
    """
    intensity_col = df.columns[-1]
    feature_cols = df.columns[:-1]
    
    # Create plots for each feature column vs intensity
    for col in feature_cols:
        create_scatter_plots(df, [col], intensity_col)
        create_minima_plots(df, [col], intensity_col)

def main(yaml_path: str, data_path: str):
    """
    Main function to process YAML and data files and create visualizations.
    Handles both single and multi-node cases.
    """
    # Load YAML data
    coordinates, strings = load_yaml_data(yaml_path)
    
    # Load data
    df = pd.read_csv(data_path)
    
    if len(coordinates) >= 2:
        # Multi-node case: process as before
        string_groups = group_strings(strings)
        matched_pairs = match_groups_to_coordinates(string_groups, coordinates)
        
        for string_group, trouble_col in matched_pairs:
            if len(string_group) == 2:
                create_scatter_plots(df, string_group, trouble_col)
                create_minima_plots(df, string_group, trouble_col)
    else:
        # Single-node case: process all columns vs last column
        process_single_node(df)

# Example usage:
"""

main('config.yaml', 'data.csv')
"""
